{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg face mask.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rg4azWJMnG0G"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import os\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import load_model\n",
        "import cv2"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdLAFa5CnGwP"
      },
      "source": [
        "\n",
        "train_f = \"/content/train\"\n",
        "test_f = \"/content/test\"\n",
        "valid_f = \"/content/validation\"\n",
        "mask_train = os.path.join(train_f,'mask')\n",
        "nomask_train = os.path.join(train_f,'nonmask')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9T1LPmBqrG2H",
        "outputId": "e062dc0d-6cbc-47af-92ec-410c0d53979c"
      },
      "source": [
        "mask_train_name = os.listdir(mask_train)\n",
        "print(mask_train_name[:25])\n",
        "nomask_train_name = os.listdir(nomask_train)\n",
        "print(nomask_train_name[:25])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0006.jpg', '0029.jpg', '0040.jpg', '0043.jpg', '0037.jpg', '0003.jpg', '0018.jpg', '0019.jpg', '0042.jpg', '0022.jpg', '0048.jpg', '0027.jpg']\n",
            "['13.jpg', '1.jpg', '0.jpg', '10.jpg', '6.jpg', '12.jpg', '11.jpg', '2.jpg', '3.jpg', '7.jpg', '4.jpg', '9.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSYSy-PXrjYX",
        "outputId": "d8e33d2e-7580-43de-ac36-9e2d644d1b56"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   zoom_range = 0.3,\n",
        "                                   rotation_range = 35,\n",
        "                                   horizontal_flip = True\n",
        "                                   )\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_f,\n",
        "                                                    target_size=(150,150),\n",
        "                                                    batch_size = 32,\n",
        "                                                    class_mode = 'binary'\n",
        "                                                    )\n",
        "test_generator = test_datagen.flow_from_directory(test_f,\n",
        "                                                    target_size=(150,150),\n",
        "                                                    batch_size = 32,\n",
        "                                                    class_mode = 'binary'\n",
        "                                                    )\n",
        "valid_generator = validation_datagen.flow_from_directory(valid_f,\n",
        "                                                    target_size=(150,150),\n",
        "                                                    batch_size = 32,\n",
        "                                                    class_mode = 'binary'\n",
        "                                                    )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 24 images belonging to 3 classes.\n",
            "Found 24 images belonging to 3 classes.\n",
            "Found 24 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KP_c3VVrjU7",
        "outputId": "b635eacd-e087-4e29-d023-add93a43a206"
      },
      "source": [
        "train_generator.class_indices"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.ipynb_checkpoints': 0, 'mask': 1, 'nonmask': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bixsfwdUrjRN",
        "outputId": "9c80b6f1-8a20-4b89-c5cb-f2c1b08d6e46"
      },
      "source": [
        "train_generator.image_shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 150, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vknw9TEpwoON"
      },
      "source": [
        "from tensorflow.keras.applications import vgg16\n",
        "\n",
        " \n",
        "\n",
        "# Init the VGG model\n",
        "\n",
        "vgg_conv = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(600, 600, 3))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65-dazBwxCPG",
        "outputId": "1af5baa9-b13b-4446-8b88-fcc98012f155"
      },
      "source": [
        "# Freeze all the layers\n",
        "\n",
        "for layer in vgg_conv.layers[:]:\n",
        "    layer.trainable = False\n",
        "\n",
        " \n",
        "\n",
        "# Check the trainable status of the individual layers\n",
        "\n",
        "for layer in vgg_conv.layers:\n",
        "    print(layer, layer.trainable)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f2e17895c10> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f2e2256c490> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f2e178a0c10> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f2e1788d250> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f2e01d4fb10> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f2e01d86a50> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f2e178a6750> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f2e178bc4d0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f2e178fa890> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f2e178fa950> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f2e178a4a50> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f2e01d74190> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f2e01681e50> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f2e018512d0> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f2e0180bfd0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f2e17898550> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f2e178983d0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f2e22566dd0> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f2e178f4610> False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWWy5wCjxCLb",
        "outputId": "d5d4b1fe-cf61-408d-c7aa-db46bd0fed95"
      },
      "source": [
        "# Create the model\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        " \n",
        "\n",
        "# Add the vgg convolutional base model\n",
        "\n",
        "model.add(vgg_conv)\n",
        "\n",
        " \n",
        "\n",
        "# Add new layers\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        " \n",
        "\n",
        "# Show a summary of the model. Check the number of trainable parameters\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 18, 18, 512)       14714688  \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 165888)            0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1024)              169870336 \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 3)                 3075      \n",
            "=================================================================\n",
            "Total params: 184,588,099\n",
            "Trainable params: 169,873,411\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkjAP8aKxCIP",
        "outputId": "bcbfb852-3d0d-4392-c768-dba368d42ed7"
      },
      "source": [
        "# Load the normalized images\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        " \n",
        "\n",
        "# Change the batchsize according to your system RAM\n",
        "\n",
        "train_batchsize = 100\n",
        "\n",
        "val_batchsize = 10\n",
        "\n",
        " \n",
        "\n",
        "# Data generator for training data\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        \"/content/train\",\n",
        "        target_size=(600, 600),\n",
        "        batch_size=10,\n",
        "        class_mode='categorical')\n",
        "\n",
        " \n",
        "\n",
        "# Data generator for validation data\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        \"/content/validation\",\n",
        "        target_size=(600, 600),\n",
        "        batch_size=10,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 24 images belonging to 3 classes.\n",
            "Found 24 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOPkw-LwxCDL",
        "outputId": "6cfaabab-3f27-4749-a219-0c4cdf5b4f5c"
      },
      "source": [
        "# Configure the model for training\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])\n",
        "\n",
        " \n",
        "\n",
        "# Train the model\n",
        "\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=\n",
        "         train_generator.samples/train_generator.batch_size,\n",
        "      epochs=20,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=\n",
        "         validation_generator.samples/validation_generator.batch_size,\n",
        "      verbose=1)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "2/2 [==============================] - 179s 114s/step - loss: 14.0793 - acc: 0.5417 - val_loss: 12.0510 - val_acc: 0.5000\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 175s 98s/step - loss: 10.0013 - acc: 0.5542 - val_loss: 10.5487 - val_acc: 0.5000\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 182s 99s/step - loss: 3.9267 - acc: 0.7500 - val_loss: 10.7845 - val_acc: 0.5000\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 175s 98s/step - loss: 4.6030 - acc: 0.6607 - val_loss: 3.7188 - val_acc: 0.5417\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 175s 99s/step - loss: 0.2358 - acc: 0.9375 - val_loss: 3.7852 - val_acc: 0.5000\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 179s 116s/step - loss: 1.3335 - acc: 0.7976 - val_loss: 1.1405 - val_acc: 0.7083\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 178s 116s/step - loss: 0.1143 - acc: 0.9613 - val_loss: 0.1056 - val_acc: 0.9583\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 174s 98s/step - loss: 1.2808e-04 - acc: 1.0000 - val_loss: 0.1263 - val_acc: 0.9583\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 174s 98s/step - loss: 4.5688e-05 - acc: 1.0000 - val_loss: 0.1375 - val_acc: 0.9583\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 183s 115s/step - loss: 1.9503e-06 - acc: 1.0000 - val_loss: 0.1373 - val_acc: 0.9583\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 174s 98s/step - loss: 2.0741e-07 - acc: 1.0000 - val_loss: 0.1365 - val_acc: 0.9583\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 174s 98s/step - loss: 2.6522e-04 - acc: 1.0000 - val_loss: 0.1507 - val_acc: 0.9167\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 181s 103s/step - loss: 2.7167e-05 - acc: 1.0000 - val_loss: 0.1477 - val_acc: 0.9583\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 176s 99s/step - loss: 3.2410e-04 - acc: 1.0000 - val_loss: 0.1716 - val_acc: 0.9167\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 174s 113s/step - loss: 1.2514e-05 - acc: 1.0000 - val_loss: 0.1718 - val_acc: 0.9167\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 175s 114s/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.3883 - val_acc: 0.8750\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 182s 99s/step - loss: 0.0045 - acc: 1.0000 - val_loss: 5.4493 - val_acc: 0.5000\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 178s 101s/step - loss: 1.1718 - acc: 0.7702 - val_loss: 0.1690 - val_acc: 0.9583\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 175s 99s/step - loss: 3.6522e-05 - acc: 1.0000 - val_loss: 0.1705 - val_acc: 0.9583\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 186s 106s/step - loss: 1.0163e-05 - acc: 1.0000 - val_loss: 0.1760 - val_acc: 0.9583\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQTXO9w-skn7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}